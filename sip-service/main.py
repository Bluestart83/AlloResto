"""
Serveur vocal IA pour prise de commande restaurant
Twilio Programmable Voice + Media Streams + OpenAI Realtime API

Architecture:
  Client appelle le num√©ro Twilio
    ‚Üí Twilio stream l'audio en WebSocket (¬µ-law 8kHz)
    ‚Üí Ce serveur proxy vers OpenAI Realtime API
    ‚Üí OpenAI r√©pond en audio
    ‚Üí Ce serveur renvoie l'audio √† Twilio
    ‚Üí Le client entend la r√©ponse
"""

import os
import json
import base64
import asyncio
import websockets
from fastapi import FastAPI, WebSocket, Request
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.websockets import WebSocketDisconnect
from twilio.twiml.voice_response import VoiceResponse, Connect, Say, Stream
from dotenv import load_dotenv
import uvicorn
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

load_dotenv()

# ============================================================
# CONFIGURATION
# ============================================================

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PORT = int(os.getenv("PORT", 5050))
VOICE = "sage"  # Options: alloy, ash, ballad, coral, echo, sage, shimmer, verse

# √âv√©nements OpenAI √† logger (pour debug)
LOG_EVENT_TYPES = [
    "error",
    "response.done",
    "input_audio_buffer.speech_started",
    "input_audio_buffer.speech_stopped",
    "response.content.done",
    "session.created",
    "session.updated",
]

# ============================================================
# MENU DU RESTAURANT (√† terme: charg√© depuis une BDD/API)
# ============================================================

RESTAURANT_NAME = "Chez Marco"

MENU = """
üçï PIZZAS:
- Margherita: 9‚Ç¨
- Quatre Fromages: 11‚Ç¨ 
- Regina (jambon, champignons): 10‚Ç¨
- Calzone: 12‚Ç¨

ü•ó SALADES:
- C√©sar: 8‚Ç¨
- Italienne: 7‚Ç¨

üçù P√ÇTES:
- Carbonara: 10‚Ç¨
- Bolognaise: 9‚Ç¨
- Pesto: 9‚Ç¨

ü•§ BOISSONS:
- Coca-Cola (33cl): 2.50‚Ç¨
- Orangina (33cl): 2.50‚Ç¨
- Eau min√©rale (50cl): 1.50‚Ç¨
- Bi√®re pression (25cl): 3‚Ç¨

üç∞ DESSERTS:
- Tiramisu: 6‚Ç¨
- Panna Cotta: 5‚Ç¨
"""

# ============================================================
# SYSTEM PROMPT - Le c≈ìur de l'IA
# ============================================================

SYSTEM_MESSAGE = f"""
Tu es l'assistant vocal de "{RESTAURANT_NAME}" pour la prise de commande t√©l√©phonique.

## Ton r√¥le
- Accueillir chaleureusement le client
- Prendre sa commande √† partir du menu
- Confirmer chaque article ajout√©
- R√©capituler la commande compl√®te avec le total
- Demander si c'est pour livraison ou retrait sur place
- Si livraison: demander l'adresse et le num√©ro de t√©l√©phone
- Proposer un cr√©neau de retrait/livraison (30-45 min)

## Le menu
{MENU}

## R√®gles importantes
- Parle TOUJOURS en fran√ßais
- Sois naturel, chaleureux et concis (c'est un appel t√©l√©phone, pas un chat)
- Si le client demande quelque chose hors menu, dis poliment que ce n'est pas disponible
- Calcule toujours le total au fur et √† mesure
- Quand la commande est finalis√©e, utilise la fonction confirm_order pour l'enregistrer
- Tu peux g√©rer les modifications ("en fait non, remplace la Margherita par une Calzone")
- Si le client demande des infos (horaires, allerg√®nes), r√©ponds au mieux

## Style vocal
- Phrases courtes
- Pas de listes √† puces (c'est de l'audio!)
- Confirme chaque item: "Parfait, une Margherita √† 9 euros, c'est not√©!"
- R√©capitule naturellement: "Alors on a une Margherita, une C√©sar et deux Cocas, √ßa fait 22 euros au total"

## Horaires
Le restaurant est ouvert du mardi au dimanche, de 11h30 √† 14h et de 18h30 √† 22h30.
Livraison possible dans un rayon de 5km.
"""

# ============================================================
# TOOLS / FUNCTION CALLING
# ============================================================

TOOLS = [
    {
        "type": "function",
        "name": "confirm_order",
        "description": "Enregistre la commande finalis√©e du client. Appeler quand le client a confirm√© sa commande compl√®te.",
        "parameters": {
            "type": "object",
            "properties": {
                "items": {
                    "type": "array",
                    "description": "Liste des articles command√©s",
                    "items": {
                        "type": "object",
                        "properties": {
                            "name": {"type": "string", "description": "Nom de l'article"},
                            "quantity": {"type": "integer", "description": "Quantit√©"},
                            "unit_price": {"type": "number", "description": "Prix unitaire en euros"},
                            "notes": {"type": "string", "description": "Modifications (ex: sans oignons)"},
                        },
                        "required": ["name", "quantity", "unit_price"],
                    },
                },
                "total": {"type": "number", "description": "Total de la commande en euros"},
                "order_type": {
                    "type": "string",
                    "enum": ["pickup", "delivery"],
                    "description": "Retrait sur place ou livraison",
                },
                "customer_name": {"type": "string", "description": "Nom du client"},
                "customer_phone": {"type": "string", "description": "Num√©ro de t√©l√©phone du client"},
                "delivery_address": {"type": "string", "description": "Adresse de livraison (si livraison)"},
                "estimated_time": {"type": "string", "description": "Heure estim√©e de retrait/livraison"},
            },
            "required": ["items", "total", "order_type"],
        },
    }
]

# ============================================================
# FASTAPI APP
# ============================================================

app = FastAPI()


@app.get("/", response_class=HTMLResponse)
async def index():
    return "<h1>üçï Serveur vocal {}</h1><p>Le serveur tourne. Appelez le num√©ro Twilio!</p>".format(
        RESTAURANT_NAME
    )


@app.api_route("/incoming-call", methods=["GET", "POST"])
async def incoming_call(request: Request):
    """
    Twilio appelle cette URL quand un appel arrive.
    On r√©pond avec du TwiML qui connecte l'appel √† notre WebSocket.
    """
    response = VoiceResponse()
    response.say(
        f"Bienvenue chez {RESTAURANT_NAME}, veuillez patienter, je vous mets en relation avec notre assistant.",
        voice="Google.fr-FR-Wavenet-A",
        language="fr-FR",
    )
    response.pause(length=1)

    host = request.headers.get("host", request.url.hostname)
    connect = Connect()
    stream = Stream(url=f"wss://{host}/media-stream")
    connect.append(stream)
    response.append(connect)

    return HTMLResponse(content=str(response), media_type="application/xml")


@app.websocket("/media-stream")
async def media_stream(websocket: WebSocket):
    """
    WebSocket bidirectionnel:
    - Re√ßoit l'audio de Twilio (¬µ-law 8kHz, base64)
    - Envoie √† OpenAI Realtime API
    - Re√ßoit la r√©ponse audio d'OpenAI
    - Renvoie √† Twilio
    """
    await websocket.accept()
    logger.info("üìû Nouvel appel connect√© au WebSocket")

    # Connexion √† OpenAI Realtime API
    openai_ws_url = "wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-12-17"
    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "OpenAI-Beta": "realtime=v1",
    }

    async with websockets.connect(openai_ws_url, additional_headers=headers) as openai_ws:
        # State
        stream_sid = None
        latest_media_timestamp = 0
        last_assistant_item = None
        mark_queue = []
        response_start_timestamp_twilio = None

        # Envoyer la config de session √† OpenAI
        await send_session_update(openai_ws)
        logger.info("‚úÖ Session OpenAI configur√©e")

        # ------------------------------------------------
        # TASK 1: Recevoir l'audio de Twilio ‚Üí OpenAI
        # ------------------------------------------------
        async def receive_from_twilio():
            nonlocal stream_sid, latest_media_timestamp
            try:
                async for message in websocket.iter_text():
                    data = json.loads(message)

                    if data["event"] == "media" and openai_ws.open:
                        latest_media_timestamp = int(data["media"]["timestamp"])
                        audio_append = {
                            "type": "input_audio_buffer.append",
                            "audio": data["media"]["payload"],
                        }
                        await openai_ws.send(json.dumps(audio_append))

                    elif data["event"] == "start":
                        stream_sid = data["start"]["streamSid"]
                        logger.info(f"üì° Stream d√©marr√©: {stream_sid}")
                        latest_media_timestamp = 0
                        response_start_timestamp_twilio = None

                    elif data["event"] == "mark":
                        if mark_queue:
                            mark_queue.pop(0)

            except WebSocketDisconnect:
                logger.info("üì¥ Client d√©connect√©")
                if openai_ws.open:
                    await openai_ws.close()

        # ------------------------------------------------
        # TASK 2: Recevoir la r√©ponse d'OpenAI ‚Üí Twilio
        # ------------------------------------------------
        async def send_to_twilio():
            nonlocal stream_sid, last_assistant_item, response_start_timestamp_twilio

            try:
                async for openai_message in openai_ws:
                    response = json.loads(openai_message)
                    response_type = response.get("type", "")

                    if response_type in LOG_EVENT_TYPES:
                        logger.info(f"ü§ñ OpenAI event: {response_type}")

                    # Audio de la r√©ponse ‚Üí renvoyer √† Twilio
                    if response_type == "response.audio.delta" and "delta" in response:
                        audio_payload = base64.b64encode(
                            base64.b64decode(response["delta"])
                        ).decode("utf-8")
                        audio_delta = {
                            "event": "media",
                            "streamSid": stream_sid,
                            "media": {"payload": audio_payload},
                        }
                        await websocket.send_json(audio_delta)

                        if response_start_timestamp_twilio is None:
                            response_start_timestamp_twilio = latest_media_timestamp

                    # Gestion des interruptions (le client parle pendant que l'IA parle)
                    if response_type == "input_audio_buffer.speech_started":
                        logger.info("üó£Ô∏è Client interrompt l'IA")
                        await handle_speech_started_event(
                            websocket, openai_ws, stream_sid, 
                            response_start_timestamp_twilio, latest_media_timestamp,
                            last_assistant_item, mark_queue
                        )
                        response_start_timestamp_twilio = None

                    # Track le dernier item assistant pour les interruptions
                    if response_type == "response.output_item.added":
                        item = response.get("item", {})
                        if item.get("role") == "assistant":
                            last_assistant_item = item.get("id")

                    # Function calling - commande confirm√©e!
                    if response_type == "response.function_call_arguments.done":
                        await handle_function_call(response, openai_ws)

                    if response_type == "response.audio.done":
                        # Marquer la fin de la r√©ponse audio
                        mark_event = {
                            "event": "mark",
                            "streamSid": stream_sid,
                            "mark": {"name": "responsePart"},
                        }
                        await websocket.send_json(mark_event)
                        mark_queue.append("responsePart")

            except Exception as e:
                logger.error(f"‚ùå Erreur OpenAI: {e}")

        # Lancer les deux t√¢ches en parall√®le
        await asyncio.gather(receive_from_twilio(), send_to_twilio())


# ============================================================
# HELPERS
# ============================================================


async def send_session_update(openai_ws):
    """Configure la session OpenAI Realtime avec le prompt resto et les tools."""
    session_update = {
        "type": "session.update",
        "session": {
            "turn_detection": {"type": "server_vad"},
            "input_audio_format": "g711_ulaw",
            "output_audio_format": "g711_ulaw",
            "voice": VOICE,
            "instructions": SYSTEM_MESSAGE,
            "modalities": ["text", "audio"],
            "temperature": 0.7,
            "tools": TOOLS,
            "tool_choice": "auto",
            "input_audio_transcription": {
                "model": "whisper-1",
            },
        },
    }
    await openai_ws.send(json.dumps(session_update))

    # D√©clencher le message d'accueil
    initial_conversation_item = {
        "type": "conversation.item.create",
        "item": {
            "type": "message",
            "role": "user",
            "content": [
                {
                    "type": "input_text",
                    "text": "Salue le client qui vient d'appeler. Pr√©sente-toi bri√®vement et demande-lui ce qu'il souhaite commander. Sois chaleureux et concis.",
                }
            ],
        },
    }
    await openai_ws.send(json.dumps(initial_conversation_item))
    await openai_ws.send(json.dumps({"type": "response.create"}))


async def handle_speech_started_event(
    websocket, openai_ws, stream_sid, 
    response_start_timestamp_twilio, latest_media_timestamp,
    last_assistant_item, mark_queue
):
    """G√®re l'interruption: le client parle pendant que l'IA r√©pond."""
    if mark_queue and response_start_timestamp_twilio is not None:
        elapsed_time = latest_media_timestamp - response_start_timestamp_twilio

        # Vider le buffer audio de Twilio
        await websocket.send_json({"event": "clear", "streamSid": stream_sid})

        # Tronquer la r√©ponse OpenAI
        if last_assistant_item:
            truncate_event = {
                "type": "conversation.item.truncate",
                "item_id": last_assistant_item,
                "content_index": 0,
                "audio_end_ms": elapsed_time,
            }
            await openai_ws.send(json.dumps(truncate_event))

        mark_queue.clear()


async def handle_function_call(response, openai_ws):
    """
    Traite les function calls d'OpenAI (ex: confirm_order).
    C'est ici que tu envoies la commande √† ton dashboard Next.js!
    """
    function_name = response.get("name", "")
    call_id = response.get("call_id", "")
    
    try:
        arguments = json.loads(response.get("arguments", "{}"))
    except json.JSONDecodeError:
        arguments = {}

    logger.info(f"üìã Function call: {function_name}")
    logger.info(f"üì¶ Arguments: {json.dumps(arguments, indent=2, ensure_ascii=False)}")

    if function_name == "confirm_order":
        # =============================================
        # üöÄ ICI: Envoie la commande √† ton backend!
        # =============================================
        # Exemples:
        # - POST vers ton API Next.js
        # - WebSocket vers ton dashboard
        # - Sauvegarde en BDD
        # - Envoi d'une notification push au resto
        #
        # import httpx
        # async with httpx.AsyncClient() as client:
        #     await client.post("https://ton-dashboard.com/api/orders", json=arguments)
        
        order_total = arguments.get("total", 0)
        items_count = len(arguments.get("items", []))
        
        logger.info(f"‚úÖ COMMANDE CONFIRM√âE: {items_count} articles, total {order_total}‚Ç¨")

        # R√©pondre √† OpenAI que la fonction a r√©ussi
        function_output = {
            "type": "conversation.item.create",
            "item": {
                "type": "function_call_output",
                "call_id": call_id,
                "output": json.dumps({
                    "success": True,
                    "order_id": "CMD-" + str(hash(json.dumps(arguments)))[-6:],
                    "message": f"Commande de {order_total}‚Ç¨ enregistr√©e avec succ√®s",
                    "estimated_time": "35 minutes",
                }),
            },
        }
        await openai_ws.send(json.dumps(function_output))
        await openai_ws.send(json.dumps({"type": "response.create"}))


# ============================================================
# ENTRY POINT
# ============================================================

if __name__ == "__main__":
    if not OPENAI_API_KEY:
        raise ValueError("‚ùå OPENAI_API_KEY manquant dans .env")
    
    logger.info(f"üçï Serveur vocal '{RESTAURANT_NAME}' d√©marr√© sur le port {PORT}")
    logger.info(f"üìû Configurez Twilio webhook vers: https://VOTRE_DOMAINE/incoming-call")
    
    uvicorn.run(app, host="0.0.0.0", port=PORT)
